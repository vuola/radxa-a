apiVersion: v1
kind: Namespace
metadata:
  name: weather
  labels:
    name: weather
---
apiVersion: v1
kind: PersistentVolume
metadata:
  name: weather-postgres-pv
spec:
  capacity:
    storage: 50Gi
  accessModes:
    - ReadWriteOnce
  persistentVolumeReclaimPolicy: Retain
  storageClassName: local-ssd
  hostPath:
    path: /media/ssd250/weather/postgres
    type: DirectoryOrCreate
  nodeAffinity:
    required:
      nodeSelectorTerms:
        - matchExpressions:
            - key: kubernetes.io/hostname
              operator: In
              values:
                - radxa-a
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: weather-postgres-pvc
  namespace: weather
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 50Gi
  storageClassName: local-ssd
  volumeName: weather-postgres-pv
---
apiVersion: v1
kind: Service
metadata:
  name: weather-postgres
  namespace: weather
spec:
  type: ClusterIP
  ports:
    - name: postgres
      port: 5432
      targetPort: 5432
  selector:
    app: weather-postgres
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: weather-postgres
  namespace: weather
spec:
  serviceName: weather-postgres
  replicas: 1
  selector:
    matchLabels:
      app: weather-postgres
  template:
    metadata:
      labels:
        app: weather-postgres
    spec:
      containers:
        - name: postgres
          image: docker.io/library/postgres:16-alpine
          imagePullPolicy: IfNotPresent
          env:
            - name: POSTGRES_DB
              valueFrom:
                secretKeyRef:
                  name: weather-db
                  key: MYSQL_DATABASE
            - name: POSTGRES_USER
              valueFrom:
                secretKeyRef:
                  name: weather-db
                  key: MYSQL_USER
            - name: POSTGRES_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: weather-db
                  key: MYSQL_PASSWORD
          ports:
            - containerPort: 5432
              name: postgres
          volumeMounts:
            - name: data
              mountPath: /var/lib/postgresql/data
          livenessProbe:
            exec:
              command:
                - /bin/sh
                - -c
                - pg_isready -U "$POSTGRES_USER" -d "$POSTGRES_DB"
            initialDelaySeconds: 30
            periodSeconds: 10
          readinessProbe:
            exec:
              command:
                - /bin/sh
                - -c
                - pg_isready -U "$POSTGRES_USER" -d "$POSTGRES_DB"
            initialDelaySeconds: 10
            periodSeconds: 10
      volumes:
        - name: data
          persistentVolumeClaim:
            claimName: weather-postgres-pvc
---
apiVersion: batch/v1
kind: CronJob
metadata:
  name: weather-postgres-backup
  namespace: weather
spec:
  schedule: "15 2 * * *"
  jobTemplate:
    spec:
      template:
        spec:
          restartPolicy: OnFailure
          nodeSelector:
            kubernetes.io/hostname: radxa-a
          containers:
            - name: backup
              image: docker.io/library/postgres:16-alpine
              imagePullPolicy: IfNotPresent
              env:
                - name: POSTGRES_DB
                  valueFrom:
                    secretKeyRef:
                      name: weather-db
                      key: MYSQL_DATABASE
                - name: POSTGRES_USER
                  valueFrom:
                    secretKeyRef:
                      name: weather-db
                      key: MYSQL_USER
                - name: POSTGRES_PASSWORD
                  valueFrom:
                    secretKeyRef:
                      name: weather-db
                      key: MYSQL_PASSWORD
                - name: PGPASSWORD
                  valueFrom:
                    secretKeyRef:
                      name: weather-db
                      key: MYSQL_PASSWORD
              command:
                - /bin/sh
                - -c
                - |
                  set -e
                  ts=$(date +%F_%H%M%S)
                  pg_dump -h weather-postgres -U "$POSTGRES_USER" "$POSTGRES_DB" > /backups/weather_${ts}.sql
                  ls -1t /backups/weather_*.sql | tail -n +8 | xargs -r rm -f
              volumeMounts:
                - name: backups
                  mountPath: /backups
          volumes:
            - name: backups
              hostPath:
                path: /media/ssd250/weather/backups
                type: DirectoryOrCreate
---
apiVersion: batch/v1
kind: CronJob
metadata:
  name: weather-sqlite-import
  namespace: weather
spec:
  schedule: "10 0 * * *"
  jobTemplate:
    spec:
      template:
        spec:
          restartPolicy: OnFailure
          containers:
            - name: importer
              image: docker.io/library/python:3.11-slim
              imagePullPolicy: IfNotPresent
              env:
                - name: PGHOST
                  value: weather-postgres
                - name: PGDATABASE
                  valueFrom:
                    secretKeyRef:
                      name: weather-db
                      key: MYSQL_DATABASE
                - name: PGUSER
                  valueFrom:
                    secretKeyRef:
                      name: weather-db
                      key: MYSQL_USER
                - name: PGPASSWORD
                  valueFrom:
                    secretKeyRef:
                      name: weather-db
                      key: MYSQL_PASSWORD
                - name: INBOX_DIR
                  value: /var/inbox
              command:
                - /bin/sh
                - -c
                - |
                  set -e
                  python -m pip install --no-cache-dir psycopg2-binary
                  python - <<'PY'
                  import json
                  import os
                  import shutil
                  import sqlite3
                  import psycopg2
                  from psycopg2.extras import execute_batch, Json

                  inbox = os.environ.get("INBOX_DIR", "/var/inbox")
                  processed_dir = os.path.join(inbox, "processed")
                  os.makedirs(processed_dir, exist_ok=True)

                  pg_conn = psycopg2.connect(
                      host=os.environ["PGHOST"],
                      dbname=os.environ["PGDATABASE"],
                      user=os.environ["PGUSER"],
                      password=os.environ["PGPASSWORD"],
                  )
                  pg_conn.autocommit = True
                  cur = pg_conn.cursor()
                  cur.execute(
                      """
                      CREATE TABLE IF NOT EXISTS weather (
                        id BIGSERIAL PRIMARY KEY,
                        ts TIMESTAMPTZ,
                        temperature_c DOUBLE PRECISION,
                        dew_point_c DOUBLE PRECISION,
                        relative_humidity DOUBLE PRECISION,
                        pressure_hpa DOUBLE PRECISION,
                        wind_speed_ms DOUBLE PRECISION,
                        wind_direction_deg DOUBLE PRECISION,
                        precip_mmph DOUBLE PRECISION,
                        energy_today_wh BIGINT,
                        pv_feed_in_w INTEGER,
                        battery_soc_pct INTEGER,
                        active_power_pcc_w INTEGER,
                        bat_charge_w INTEGER,
                        bat_discharge_w INTEGER,
                        sma_json JSONB,
                        merged_at TIMESTAMPTZ,
                        pushed_at TIMESTAMPTZ
                      );
                      CREATE UNIQUE INDEX IF NOT EXISTS weather_ts_unique ON weather (ts);
                      """
                  )

                  insert_sql = """
                  INSERT INTO weather (
                    ts, temperature_c, dew_point_c, relative_humidity, pressure_hpa,
                    wind_speed_ms, wind_direction_deg, precip_mmph,
                    energy_today_wh, pv_feed_in_w, battery_soc_pct, active_power_pcc_w,
                    bat_charge_w, bat_discharge_w, sma_json, merged_at, pushed_at
                  ) VALUES (
                    %(ts)s, %(temperature_c)s, %(dew_point_c)s, %(relative_humidity)s, %(pressure_hpa)s,
                    %(wind_speed_ms)s, %(wind_direction_deg)s, %(precip_mmph)s,
                    %(energy_today_wh)s, %(pv_feed_in_w)s, %(battery_soc_pct)s, %(active_power_pcc_w)s,
                    %(bat_charge_w)s, %(bat_discharge_w)s, %(sma_json)s, %(merged_at)s, %(pushed_at)s
                  )
                  ON CONFLICT (ts) DO NOTHING;
                  """

                  files = sorted(
                      f for f in os.listdir(inbox)
                      if f.endswith(".db") and os.path.isfile(os.path.join(inbox, f))
                  )
                  for fname in files:
                      fpath = os.path.join(inbox, fname)
                      conn = sqlite3.connect(f"file:{fpath}?immutable=1", uri=True)
                      try:
                          scur = conn.cursor()
                          tables = scur.execute(
                              "SELECT name FROM sqlite_master WHERE type='table' AND name='weather'"
                          ).fetchall()
                          if not tables:
                              continue
                          scur.execute(
                              "SELECT ts, temperature_c, dew_point_c, relative_humidity, pressure_hpa, "
                              "wind_speed_ms, wind_direction_deg, precip_mmph, energy_today_wh, pv_feed_in_w, "
                              "battery_soc_pct, active_power_pcc_w, bat_charge_w, bat_discharge_w, sma_json, merged_at, pushed_at "
                              "FROM weather"
                          )
                          rows = []
                          for row in scur:
                              rows.append({
                                  "ts": row[0],
                                  "temperature_c": row[1],
                                  "dew_point_c": row[2],
                                  "relative_humidity": row[3],
                                  "pressure_hpa": row[4],
                                  "wind_speed_ms": row[5],
                                  "wind_direction_deg": row[6],
                                  "precip_mmph": row[7],
                                  "energy_today_wh": row[8],
                                  "pv_feed_in_w": row[9],
                                  "battery_soc_pct": row[10],
                                  "active_power_pcc_w": row[11],
                                  "bat_charge_w": row[12],
                                  "bat_discharge_w": row[13],
                                  "sma_json": Json(json.loads(row[14])) if row[14] else None,
                                  "merged_at": row[15],
                                  "pushed_at": row[16],
                              })
                          if rows:
                              execute_batch(cur, insert_sql, rows, page_size=500)
                      finally:
                          conn.close()
                      shutil.move(fpath, os.path.join(processed_dir, fname))
                  cur.close()
                  pg_conn.close()
                  PY
              volumeMounts:
                - name: inbox
                  mountPath: /var/inbox
          volumes:
            - name: inbox
              hostPath:
                path: /media/ssd250/weather/inbox
                type: DirectoryOrCreate
---
apiVersion: batch/v1
kind: CronJob
metadata:
  name: entsoe-dayahead-import
  namespace: weather
spec:
  schedule: "10 14,15,16 * * *"
  jobTemplate:
    spec:
      template:
        spec:
          restartPolicy: OnFailure
          containers:
            - name: entsoe-importer
              image: docker.io/library/python:3.11-slim
              imagePullPolicy: IfNotPresent
              env:
                - name: PGHOST
                  value: weather-postgres
                - name: PGDATABASE
                  valueFrom:
                    secretKeyRef:
                      name: weather-db
                      key: MYSQL_DATABASE
                - name: PGUSER
                  valueFrom:
                    secretKeyRef:
                      name: weather-db
                      key: MYSQL_USER
                - name: PGPASSWORD
                  valueFrom:
                    secretKeyRef:
                      name: weather-db
                      key: MYSQL_PASSWORD
                - name: ENTSOE_API_KEY
                  valueFrom:
                    secretKeyRef:
                      name: entsoe-api
                      key: API_KEY
                - name: ENTSOE_IN_DOMAIN
                  value: 10YFI-1--------U
                - name: ENTSOE_OUT_DOMAIN
                  value: 10YFI-1--------U
                - name: ENTSOE_MARKET_AGREEMENT
                  value: A01
                - name: ENTSOE_TZ
                  value: Europe/Helsinki
              command:
                - /bin/bash
                - -c
              args:
                - |
                  set -e
                  python -m pip install --no-cache-dir psycopg2-binary requests
                  python /opt/entsoe/entsoe_import.py
              volumeMounts:
                - name: entsoe-importer-script
                  mountPath: /opt/entsoe/entsoe_import.py
                  subPath: entsoe_import.py
          volumes:
            - name: entsoe-importer-script
              configMap:
                name: entsoe-importer-script
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: entsoe-importer-script
  namespace: weather
data:
  entsoe_import.py: |-
    import os
    import sys
    import xml.etree.ElementTree as ET
    from datetime import datetime, timedelta, timezone, time
    from zoneinfo import ZoneInfo

    import psycopg2
    from psycopg2.extras import execute_batch
    import requests

    print("Starting ENTSO-E import script", file=sys.stderr, flush=True)

    api_key = os.environ["ENTSOE_API_KEY"]
    in_domain = os.environ.get("ENTSOE_IN_DOMAIN", "10YFI-1--------U")
    out_domain = os.environ.get("ENTSOE_OUT_DOMAIN", "10YFI-1--------U")
    market_agreement = os.environ.get("ENTSOE_MARKET_AGREEMENT", "A01")
    local_tz = ZoneInfo(os.environ.get("ENTSOE_TZ", "Europe/Helsinki"))

    now_local = datetime.now(local_tz)
    target_day = (now_local + timedelta(days=1)).date()
    start_local = datetime.combine(target_day, time(0, 0), tzinfo=local_tz)
    end_local = start_local + timedelta(days=1)
    start_utc = start_local.astimezone(timezone.utc)
    end_utc = end_local.astimezone(timezone.utc)

    def fmt(dt: datetime) -> str:
        return dt.strftime("%Y%m%d%H%M")

    params = {
        "securityToken": api_key,
        "documentType": "A44",
        "in_Domain": in_domain,
        "out_Domain": out_domain,
        "contract_MarketAgreement.type": market_agreement,
        "periodStart": fmt(start_utc),
        "periodEnd": fmt(end_utc),
    }

    resp = requests.get("https://web-api.tp.entsoe.eu/api", params=params, timeout=60)
    resp.raise_for_status()

    root = ET.fromstring(resp.content)

    def parse_resolution(res_text: str) -> timedelta:
        if res_text == "PT15M":
            return timedelta(minutes=15)
        if res_text == "PT30M":
            return timedelta(minutes=30)
        if res_text == "PT60M":
            return timedelta(minutes=60)
        raise ValueError(f"Unsupported resolution: {res_text}")

    price_by_ts = {}
    for ts_node in root.findall(".//{*}TimeSeries"):
        for period in ts_node.findall(".//{*}Period"):
            start_text = period.findtext("{*}timeInterval/{*}start")
            res_text = period.findtext("{*}resolution")
            if not start_text or not res_text:
                continue
            if start_text.endswith("Z"):
                start_text = start_text.replace("Z", "+00:00")
            period_start = datetime.fromisoformat(start_text)
            resolution = parse_resolution(res_text)
            for point in period.findall("{*}Point"):
                pos_text = point.findtext("{*}position")
                price_text = point.findtext("{*}price.amount")
                if not pos_text or price_text is None:
                    continue
                pos = int(pos_text)
                ts = period_start + (pos - 1) * resolution
                ts_utc = ts.astimezone(timezone.utc)
                price_by_ts[ts_utc] = float(price_text)

    if not price_by_ts:
        raise SystemExit("No price rows returned by ENTSO-E")

    rows = []
    ts = start_utc
    last_price = None
    while ts < end_utc:
        price = price_by_ts.get(ts)
        if price is None:
            price = last_price
        else:
            last_price = price
        rows.append((ts.isoformat(), price))
        ts += timedelta(minutes=15)

    pg_conn = psycopg2.connect(
        host=os.environ["PGHOST"],
        dbname=os.environ["PGDATABASE"],
        user=os.environ["PGUSER"],
        password=os.environ["PGPASSWORD"],
    )
    pg_conn.autocommit = True
    cur = pg_conn.cursor()
    cur.execute(
        """
        CREATE TABLE IF NOT EXISTS entsoe_prices (
          ts TIMESTAMPTZ PRIMARY KEY,
          price_eur_per_mwh DOUBLE PRECISION NULL,
          created_at TIMESTAMPTZ NOT NULL DEFAULT now(),
          updated_at TIMESTAMPTZ NOT NULL DEFAULT now(),
          CONSTRAINT entsoe_prices_ts_15m CHECK (
            date_trunc('minute', ts) = ts
            AND date_part('minute', ts) IN (0, 15, 30, 45)
          )
        );
        """
    )
    insert_sql = """
    INSERT INTO entsoe_prices (ts, price_eur_per_mwh)
    VALUES (%s, %s)
    ON CONFLICT (ts) DO UPDATE
      SET price_eur_per_mwh = EXCLUDED.price_eur_per_mwh,
          updated_at = now();
    """
    execute_batch(cur, insert_sql, rows, page_size=500)
    print(f"Successfully imported {len(rows)} price rows", file=sys.stderr, flush=True)
    cur.close()
    pg_conn.close()
    print("ENTSO-E import complete", file=sys.stderr, flush=True)
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: weather-web-config
  namespace: weather
data:
  nginx.conf: |-
    server {
      listen 0.0.0.0:8080;
      server_name _;

      client_max_body_size 256m;

      root /app;
      index index.php;

      location / {
        try_files $uri /index.php?$query_string;
      }

      location ~ \.php$ {
        fastcgi_pass 127.0.0.1:9000;
        fastcgi_index index.php;
        include fastcgi_params;
        fastcgi_param SCRIPT_FILENAME /app$fastcgi_script_name;
      }
    }
  index.php: |-
    <?php
    $readSecret = function(string $path, string $fallback = ''): string {
      if (is_readable($path)) {
        return trim((string)file_get_contents($path));
      }
      return $fallback;
    };

    $host = getenv('DB_HOST') ?: 'weather-postgres';
    $db = getenv('DB_NAME') ?: $readSecret('/var/secret/MYSQL_DATABASE', 'weather');
    $user = getenv('DB_USER') ?: $readSecret('/var/secret/MYSQL_USER', 'weather');
    $pass = getenv('DB_PASS') ?: $readSecret('/var/secret/MYSQL_PASSWORD', '');

    $dsn = "pgsql:host={$host};dbname={$db}";

    try {
        $pdo = new PDO($dsn, $user, $pass, [PDO::ATTR_ERRMODE => PDO::ERRMODE_EXCEPTION]);
    } catch (Throwable $e) {
        http_response_code(500);
        echo "DB connection failed";
        exit;
    }

    $pdo->exec("CREATE TABLE IF NOT EXISTS weather (id BIGSERIAL PRIMARY KEY, ts TIMESTAMPTZ DEFAULT now(), temperature_c DOUBLE PRECISION NULL, dew_point_c DOUBLE PRECISION NULL, relative_humidity DOUBLE PRECISION NULL, pressure_hpa DOUBLE PRECISION NULL, wind_speed_ms DOUBLE PRECISION NULL, wind_direction_deg DOUBLE PRECISION NULL, precip_mmph DOUBLE PRECISION NULL, energy_today_wh BIGINT NULL, pv_feed_in_w INTEGER NULL, battery_soc_pct INTEGER NULL, active_power_pcc_w INTEGER NULL, bat_charge_w INTEGER NULL, bat_discharge_w INTEGER NULL, sma_json JSONB NULL, merged_at TIMESTAMPTZ NULL, pushed_at TIMESTAMPTZ NULL)");
    $pdo->exec("CREATE TABLE IF NOT EXISTS entsoe_prices (ts TIMESTAMPTZ PRIMARY KEY, price_eur_per_mwh DOUBLE PRECISION NULL, created_at TIMESTAMPTZ NOT NULL DEFAULT now(), updated_at TIMESTAMPTZ NOT NULL DEFAULT now(), CONSTRAINT entsoe_prices_ts_15m CHECK (date_trunc('minute', ts) = ts AND date_part('minute', ts) IN (0, 15, 30, 45)) )");
    $count = $pdo->query("SELECT COUNT(*) AS c FROM weather")->fetch(PDO::FETCH_ASSOC);

    header('Content-Type: text/html; charset=utf-8');
    echo "<h1>Weather archive</h1>";
    echo "<p>Rows in database: " . htmlspecialchars($count['c'] ?? '0') . "</p>";
    echo "<p>POST JSON to /ingest.php or upload a sqlite file using field name 'sqlite'.</p>";
    ?>
  ingest.php: |-
    <?php
    if ($_SERVER['REQUEST_METHOD'] !== 'POST') {
        http_response_code(405);
        echo "Use POST";
        exit;
    }

    if (!empty($_FILES['sqlite']['tmp_name'])) {
        $targetDir = '/var/inbox';
        if (!is_dir($targetDir)) {
            mkdir($targetDir, 0775, true);
        }
        $target = $targetDir . '/' . basename($_FILES['sqlite']['name']);
        if (!move_uploaded_file($_FILES['sqlite']['tmp_name'], $target)) {
            http_response_code(500);
            echo "Failed to save upload";
            exit;
        }
        echo "Saved to inbox";
        exit;
    }

    $payload = file_get_contents('php://input');
    $items = json_decode($payload, true);
    if (!is_array($items)) {
        http_response_code(400);
        echo "Invalid JSON";
        exit;
    }

    $readSecret = function(string $path, string $fallback = ''): string {
      if (is_readable($path)) {
        return trim((string)file_get_contents($path));
      }
      return $fallback;
    };

    $host = getenv('DB_HOST') ?: 'weather-postgres';
    $db = getenv('DB_NAME') ?: $readSecret('/var/secret/MYSQL_DATABASE', 'weather');
    $user = getenv('DB_USER') ?: $readSecret('/var/secret/MYSQL_USER', 'weather');
    $pass = getenv('DB_PASS') ?: $readSecret('/var/secret/MYSQL_PASSWORD', '');

    $dsn = "pgsql:host={$host};dbname={$db}";

    try {
        $pdo = new PDO($dsn, $user, $pass, [PDO::ATTR_ERRMODE => PDO::ERRMODE_EXCEPTION]);
    } catch (Throwable $e) {
        http_response_code(500);
        echo "DB connection failed";
        exit;
    }

    $pdo->exec("CREATE TABLE IF NOT EXISTS weather (id BIGSERIAL PRIMARY KEY, ts TIMESTAMPTZ DEFAULT now(), temperature_c DOUBLE PRECISION NULL, dew_point_c DOUBLE PRECISION NULL, relative_humidity DOUBLE PRECISION NULL, pressure_hpa DOUBLE PRECISION NULL, wind_speed_ms DOUBLE PRECISION NULL, wind_direction_deg DOUBLE PRECISION NULL, precip_mmph DOUBLE PRECISION NULL, energy_today_wh BIGINT NULL, pv_feed_in_w INTEGER NULL, battery_soc_pct INTEGER NULL, active_power_pcc_w INTEGER NULL, bat_charge_w INTEGER NULL, bat_discharge_w INTEGER NULL, sma_json JSONB NULL, merged_at TIMESTAMPTZ NULL, pushed_at TIMESTAMPTZ NULL)");
    $pdo->exec("CREATE TABLE IF NOT EXISTS entsoe_prices (ts TIMESTAMPTZ PRIMARY KEY, price_eur_per_mwh DOUBLE PRECISION NULL, created_at TIMESTAMPTZ NOT NULL DEFAULT now(), updated_at TIMESTAMPTZ NOT NULL DEFAULT now(), CONSTRAINT entsoe_prices_ts_15m CHECK (date_trunc('minute', ts) = ts AND date_part('minute', ts) IN (0, 15, 30, 45)) )");
    $stmtWithId = $pdo->prepare("INSERT INTO weather (id, ts, temperature_c, dew_point_c, relative_humidity, pressure_hpa, wind_speed_ms, wind_direction_deg, precip_mmph, energy_today_wh, pv_feed_in_w, battery_soc_pct, active_power_pcc_w, bat_charge_w, bat_discharge_w, sma_json, merged_at, pushed_at) VALUES (:id, :ts, :temperature_c, :dew_point_c, :relative_humidity, :pressure_hpa, :wind_speed_ms, :wind_direction_deg, :precip_mmph, :energy_today_wh, :pv_feed_in_w, :battery_soc_pct, :active_power_pcc_w, :bat_charge_w, :bat_discharge_w, :sma_json, :merged_at, :pushed_at) ON CONFLICT (id) DO UPDATE SET ts=EXCLUDED.ts, temperature_c=EXCLUDED.temperature_c, dew_point_c=EXCLUDED.dew_point_c, relative_humidity=EXCLUDED.relative_humidity, pressure_hpa=EXCLUDED.pressure_hpa, wind_speed_ms=EXCLUDED.wind_speed_ms, wind_direction_deg=EXCLUDED.wind_direction_deg, precip_mmph=EXCLUDED.precip_mmph, energy_today_wh=EXCLUDED.energy_today_wh, pv_feed_in_w=EXCLUDED.pv_feed_in_w, battery_soc_pct=EXCLUDED.battery_soc_pct, active_power_pcc_w=EXCLUDED.active_power_pcc_w, bat_charge_w=EXCLUDED.bat_charge_w, bat_discharge_w=EXCLUDED.bat_discharge_w, sma_json=EXCLUDED.sma_json, merged_at=EXCLUDED.merged_at, pushed_at=EXCLUDED.pushed_at");
    $stmtNoId = $pdo->prepare("INSERT INTO weather (ts, temperature_c, dew_point_c, relative_humidity, pressure_hpa, wind_speed_ms, wind_direction_deg, precip_mmph, energy_today_wh, pv_feed_in_w, battery_soc_pct, active_power_pcc_w, bat_charge_w, bat_discharge_w, sma_json, merged_at, pushed_at) VALUES (:ts, :temperature_c, :dew_point_c, :relative_humidity, :pressure_hpa, :wind_speed_ms, :wind_direction_deg, :precip_mmph, :energy_today_wh, :pv_feed_in_w, :battery_soc_pct, :active_power_pcc_w, :bat_charge_w, :bat_discharge_w, :sma_json, :merged_at, :pushed_at)");

    $inserted = 0;
    foreach ($items as $row) {
        if (!is_array($row)) {
            continue;
        }
        $payload = [
          ':ts' => $row['ts'] ?? null,
          ':temperature_c' => $row['temperature_c'] ?? null,
          ':dew_point_c' => $row['dew_point_c'] ?? null,
          ':relative_humidity' => $row['relative_humidity'] ?? null,
          ':pressure_hpa' => $row['pressure_hpa'] ?? null,
          ':wind_speed_ms' => $row['wind_speed_ms'] ?? null,
          ':wind_direction_deg' => $row['wind_direction_deg'] ?? null,
          ':precip_mmph' => $row['precip_mmph'] ?? null,
          ':energy_today_wh' => $row['energy_today_wh'] ?? null,
          ':pv_feed_in_w' => $row['pv_feed_in_w'] ?? null,
          ':battery_soc_pct' => $row['battery_soc_pct'] ?? null,
          ':active_power_pcc_w' => $row['active_power_pcc_w'] ?? null,
          ':bat_charge_w' => $row['bat_charge_w'] ?? null,
          ':bat_discharge_w' => $row['bat_discharge_w'] ?? null,
          ':sma_json' => isset($row['sma_json']) ? json_encode($row['sma_json']) : null,
          ':merged_at' => $row['merged_at'] ?? null,
          ':pushed_at' => $row['pushed_at'] ?? null,
        ];
        if (!empty($row['id'])) {
          $payload[':id'] = $row['id'];
          $stmtWithId->execute($payload);
        } else {
          $stmtNoId->execute($payload);
        }
        $inserted++;
    }

    echo "Inserted {$inserted} rows";
    ?>
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: weather-web
  namespace: weather
spec:
  replicas: 1
  selector:
    matchLabels:
      app: weather-web
  template:
    metadata:
      labels:
        app: weather-web
    spec:
      initContainers:
        - name: inbox-permissions
          image: docker.io/library/busybox:1.36
          imagePullPolicy: IfNotPresent
          command:
            - /bin/sh
            - -c
            - |
              set -e
              mkdir -p /var/inbox
              chown 1:1 /var/inbox
              chmod 775 /var/inbox
          volumeMounts:
            - name: inbox
              mountPath: /var/inbox
      containers:
        - name: nginx
          image: docker.io/library/nginx:1.25-alpine
          imagePullPolicy: IfNotPresent
          ports:
            - containerPort: 8080
              name: http
          volumeMounts:
            - name: web-config
              mountPath: /etc/nginx/conf.d/default.conf
              subPath: nginx.conf
            - name: web-app
              mountPath: /app
        - name: phpfpm
          image: docker.io/bitnami/php-fpm:8.2.7-debian-11-r4
          imagePullPolicy: IfNotPresent
          env:
            - name: PHP_POST_MAX_SIZE
              value: 256M
            - name: PHP_UPLOAD_MAX_FILESIZE
              value: 256M
            - name: DB_HOST
              value: weather-postgres.weather.svc.cluster.local
            - name: DB_NAME
              valueFrom:
                secretKeyRef:
                  name: weather-db
                  key: MYSQL_DATABASE
            - name: DB_USER
              valueFrom:
                secretKeyRef:
                  name: weather-db
                  key: MYSQL_USER
            - name: DB_PASS
              valueFrom:
                secretKeyRef:
                  name: weather-db
                  key: MYSQL_PASSWORD
          ports:
            - containerPort: 9000
              name: fastcgi
          volumeMounts:
            - name: web-app
              mountPath: /app
            - name: inbox
              mountPath: /var/inbox
            - name: db-secret
              mountPath: /var/secret
      volumes:
        - name: web-config
          configMap:
            name: weather-web-config
            items:
              - key: nginx.conf
                path: nginx.conf
        - name: web-app
          configMap:
            name: weather-web-config
            items:
              - key: index.php
                path: index.php
              - key: ingest.php
                path: ingest.php
        - name: inbox
          hostPath:
            path: /media/ssd250/weather/inbox
            type: DirectoryOrCreate
        - name: db-secret
          secret:
            secretName: weather-db
---
apiVersion: v1
kind: Service
metadata:
  name: weather-web
  namespace: weather
spec:
  type: ClusterIP
  selector:
    app: weather-web
  ports:
    - name: http
      port: 80
      targetPort: 8080
---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: weather-web
  namespace: weather
  annotations:
    kubernetes.io/ingress.class: "traefik"
spec:
  rules:
    - host: radxa-a.local
      http:
        paths:
          - path: /
            pathType: Prefix
            backend:
              service:
                name: weather-web
                port:
                  number: 80

---
apiVersion: v1
kind: ConfigMap
metadata:
  name: mosquitto-config
  namespace: weather
data:
  mosquitto.conf: |
    persistence true
    persistence_location /mosquitto/data/
    autosave_interval 30

    listener 1883
    allow_anonymous true

    log_dest stdout
---
apiVersion: v1
kind: PersistentVolume
metadata:
  name: mosquitto-pv
spec:
  capacity:
    storage: 1Gi
  accessModes:
    - ReadWriteOnce
  persistentVolumeReclaimPolicy: Retain
  storageClassName: local-ssd
  hostPath:
    path: /media/ssd250/weather/mosquitto
    type: DirectoryOrCreate
  nodeAffinity:
    required:
      nodeSelectorTerms:
        - matchExpressions:
            - key: kubernetes.io/hostname
              operator: In
              values:
                - radxa-a
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: mosquitto-data
  namespace: weather
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 1Gi
  storageClassName: local-ssd
  volumeName: mosquitto-pv
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: mosquitto
  namespace: weather
spec:
  replicas: 1
  selector:
    matchLabels:
      app: mosquitto
  template:
    metadata:
      labels:
        app: mosquitto
    spec:
      containers:
        - name: mosquitto
          image: eclipse-mosquitto:2
          ports:
            - containerPort: 1883
          volumeMounts:
            - name: config
              mountPath: /mosquitto/config/mosquitto.conf
              subPath: mosquitto.conf
            - name: data
              mountPath: /mosquitto/data
      volumes:
        - name: config
          configMap:
            name: mosquitto-config
        - name: data
          persistentVolumeClaim:
            claimName: mosquitto-data
---
apiVersion: v1
kind: Service
metadata:
  name: mqtt
  namespace: weather
spec:
  type: ClusterIP
  selector:
    app: mosquitto
  ports:
    - port: 1883
      targetPort: 1883
---
apiVersion: v1
kind: Service
metadata:
  name: mqtt-nodeport
  namespace: weather
spec:
  type: NodePort
  selector:
    app: mosquitto
  ports:
    - port: 1883
      targetPort: 1883
      nodePort: 31884
